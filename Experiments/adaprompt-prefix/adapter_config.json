{
  "config": {
    "architecture": "union",
    "configs": [
      {
        "architecture": "prefix_tuning",
        "bottleneck_size": 16,
        "cross_prefix": true,
        "dropout": 0.0,
        "encoder_prefix": true,
        "flat": false,
        "leave_out": [],
        "non_linearity": "tanh",
        "prefix_length": 40,
        "shared_gating": true,
        "use_gating": false
      }
    ]
  },
  "hidden_size": 768,
  "model_class": "GPT2LMHeadModel",
  "model_name": "gpt2",
  "model_type": "gpt2",
  "name": "sst",
  "version": "3.2.1"
}