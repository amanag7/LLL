Not all gpus support fp16 training! Will use fp32 instead.
2023-06-11 11:58:40,362 - 0:00:24 - 0.0s - INFO - __main__ - args = Namespace(adam_epsilon=0.0001, add_task_tokens=False, data_dir='../../data', debug=False, decay_style='linear', device_ids=[0], dynamic_epochs=False, fp32=False, gen_lm_sample_percentage=0.0, learning_rate=6.25e-05, lm_lambda=0.0, logging_steps=1000, lr_schedule='warmup_linear', max_grad_norm=1, max_len=1024, max_n_epochs=9, memory_sizes=[40537.0], min_batch_size=4, min_n_steps=1500, model_dir_root='../../model_cm2/gpt2/lll/sst_srl_zre_woz.en_0.0', model_name='gpt2', n_gpus=1, n_train_epochs={'sst': 20, 'srl': 20, 'zre': 20, 'woz.en': 20}, n_warmup_ratio=0.005, n_workers=25, qp_margin=0.5, real_sample=False, reg_lambda=1.0, seed=42, seq_train_type='lll', skip_tasks=None, tasks=['sst', 'srl', 'zre', 'woz.en'], temperature_lm=1.0, temperature_qa=1.0, test_batch_size=[14187], tokens_weight=5, top_k_lm=20, top_k_qa=20, top_p_lm=0.0, top_p_qa=0.0, train_batch_size=[14187], unbound=0, use_sep=False, weight_decay=0.01)
2023-06-11 11:59:01,867 - 0:00:45 - 21.5s - INFO - __main__ - task: sst, epoch: 20
2023-06-11 11:59:01,867 - 0:00:45 - 0.0s - INFO - __main__ - start to test { task: sst (load) sst (eval), seq train type: lll }
2023-06-11 11:59:02,950 - 0:00:47 - 1.1s - INFO - __main__ - len of test dataset: 1821
2023-06-11 11:59:05,596 - 0:00:49 - 2.6s - INFO - __main__ - start to test { task: sst (load) srl (eval), seq train type: lll }
2023-06-11 11:59:06,928 - 0:00:51 - 1.3s - INFO - __main__ - len of test dataset: 2201
2023-06-11 12:06:27,909 - 0:08:11 - 441.0s - INFO - __main__ - start to test { task: sst (load) zre (eval), seq train type: lll }
2023-06-11 12:06:29,623 - 0:08:13 - 1.7s - INFO - __main__ - len of test dataset: 12000
2023-06-11 12:43:59,800 - 0:45:43 - 2250.2s - INFO - __main__ - start to test { task: sst (load) woz.en (eval), seq train type: lll }
2023-06-11 12:44:00,882 - 0:45:44 - 1.1s - INFO - __main__ - len of test dataset: 1646
2023-06-11 12:47:48,069 - 0:49:32 - 227.2s - INFO - __main__ - score: {'sst': OrderedDict([('em', 79.8462383305876), ('nf1', 79.8462383305876), ('nem', 79.8462383305876)]), 'srl': OrderedDict([('em', 0.0), ('nf1', 0.02451987913141934), ('nem', 0.0)]), 'zre': OrderedDict([('em', 0.0), ('nf1', 0.0), ('nem', 0.0), ('corpus_f1', 0.0), ('precision', 0.0), ('recall', 0.0)]), 'woz.en': OrderedDict([('em', 0.0), ('nf1', 0.0), ('nem', 0.0), ('joint_goal_em', 0.0), ('turn_request_em', 32.32077764277035), ('turn_goal_em', 52.308626974483595), ('avg_dialogue', 16.160388821385176)])}
2023-06-11 12:48:09,846 - 0:49:53 - 21.8s - INFO - __main__ - task: srl, epoch: 20
2023-06-11 12:48:09,846 - 0:49:53 - 0.0s - INFO - __main__ - start to test { task: srl (load) sst (eval), seq train type: lll }
2023-06-11 12:48:11,035 - 0:49:55 - 1.2s - INFO - __main__ - len of test dataset: 1821
2023-06-11 12:48:13,164 - 0:49:57 - 2.1s - INFO - __main__ - start to test { task: srl (load) srl (eval), seq train type: lll }
2023-06-11 12:48:14,657 - 0:49:58 - 1.5s - INFO - __main__ - len of test dataset: 2201
2023-06-11 13:16:50,639 - 1:18:34 - 1716.0s - INFO - __main__ - start to test { task: srl (load) zre (eval), seq train type: lll }
2023-06-11 13:16:52,471 - 1:18:36 - 1.8s - INFO - __main__ - len of test dataset: 12000
2023-06-11 17:47:59,177 - 5:49:43 - 16266.7s - INFO - __main__ - start to test { task: srl (load) woz.en (eval), seq train type: lll }
2023-06-11 17:48:00,569 - 5:49:44 - 1.4s - INFO - __main__ - len of test dataset: 1646
2023-06-11 18:00:38,795 - 6:02:22 - 758.2s - INFO - __main__ - score: {'sst': OrderedDict([('em', 40.85667215815486), ('nf1', 40.85667215815486), ('nem', 40.85667215815486)]), 'srl': OrderedDict([('em', 32.212630622444344), ('nf1', 54.29751602452523), ('nem', 37.52839618355293)]), 'zre': OrderedDict([('em', 4.258333333333334), ('nf1', 15.050574671456642), ('nem', 6.191666666666666), ('corpus_f1', 8.322222222222223), ('precision', 6.241666666666667), ('recall', 12.483333333333334)]), 'woz.en': OrderedDict([('em', 0.0), ('nf1', 16.333778469963786), ('nem', 1.1543134872417984), ('joint_goal_em', 0.0), ('turn_request_em', 32.32077764277035), ('turn_goal_em', 52.308626974483595), ('avg_dialogue', 16.160388821385176)])}
2023-06-11 18:00:58,519 - 6:02:42 - 19.7s - INFO - __main__ - task: zre, epoch: 20
2023-06-11 18:00:58,520 - 6:02:42 - 0.0s - INFO - __main__ - start to test { task: zre (load) sst (eval), seq train type: lll }
2023-06-11 18:00:59,947 - 6:02:44 - 1.4s - INFO - __main__ - len of test dataset: 1821
2023-06-11 18:01:02,339 - 6:02:46 - 2.4s - INFO - __main__ - start to test { task: zre (load) srl (eval), seq train type: lll }
2023-06-11 18:01:04,117 - 6:02:48 - 1.8s - INFO - __main__ - len of test dataset: 2201
2023-06-11 18:12:54,921 - 6:14:39 - 710.8s - INFO - __main__ - start to test { task: zre (load) zre (eval), seq train type: lll }
2023-06-11 18:12:56,785 - 6:14:40 - 1.9s - INFO - __main__ - len of test dataset: 12000
