Not all gpus support fp16 training! Will use fp32 instead.
2023-06-27 20:50:44,974 - 0:00:05 - 0.0s - INFO - __main__ - args = Namespace(adam_epsilon=0.0001, add_task_tokens=False, data_dir='../../data', debug=False, decay_style='linear', device_ids=[1], dynamic_epochs=False, fp32=False, gen_lm_sample_percentage=0.0, learning_rate=6.25e-05, lm_lambda=0.0, logging_steps=1000, lr_schedule='warmup_linear', max_grad_norm=1, max_len=1024, max_n_epochs=9, memory_sizes=[40537.0], min_batch_size=4, min_n_steps=1500, model_dir_root='../../model_wandbtest/gpt2/lll/sst_srl_woz.en_0.0', model_name='gpt2', n_gpus=1, n_train_epochs={'sst': 3, 'srl': 3, 'woz.en': 3}, n_warmup_ratio=0.005, n_workers=25, qp_margin=0.5, real_sample=False, reg_lambda=1.0, seed=42, seq_train_type='lll', skip_tasks=None, tasks=['sst', 'srl', 'woz.en'], temperature_lm=1.0, temperature_qa=1.0, test_batch_size=[14187], tokens_weight=5, top_k_lm=20, top_k_qa=20, top_p_lm=0.0, top_p_qa=0.0, train_batch_size=[14187], unbound=0, use_sep=False, weight_decay=0.01)
2023-06-27 20:50:59,008 - 0:00:19 - 14.0s - INFO - __main__ - task: sst, epoch: 3
2023-06-27 20:50:59,009 - 0:00:19 - 0.0s - INFO - __main__ - start to test { task: sst (load) sst (eval), seq train type: lll }
2023-06-27 20:51:00,227 - 0:00:20 - 1.2s - INFO - __main__ - len of test dataset: 1821
2023-06-27 20:51:03,327 - 0:00:23 - 3.1s - INFO - __main__ - score: {'sst': OrderedDict([('em', 77.75947281713344), ('nf1', 77.75947281713344), ('nem', 77.75947281713344)]), 'srl': None, 'woz.en': None}
2023-06-27 20:51:14,751 - 0:00:35 - 11.4s - INFO - __main__ - task: srl, epoch: 3
2023-06-27 20:51:14,751 - 0:00:35 - 0.0s - INFO - __main__ - start to test { task: srl (load) srl (eval), seq train type: lll }
2023-06-27 20:51:16,194 - 0:00:36 - 1.4s - INFO - __main__ - len of test dataset: 2201
2023-06-27 21:20:50,706 - 0:30:11 - 1774.5s - INFO - __main__ - score: {'sst': None, 'srl': OrderedDict([('em', 28.759654702407992), ('nf1', 49.21561112197318), ('nem', 33.16674238982281)]), 'woz.en': None}
2023-06-27 21:21:04,789 - 0:30:25 - 14.1s - INFO - __main__ - task: woz.en, epoch: 3
2023-06-27 21:21:04,790 - 0:30:25 - 0.0s - INFO - __main__ - start to test { task: woz.en (load) woz.en (eval), seq train type: lll }
2023-06-27 21:21:07,047 - 0:30:27 - 2.3s - INFO - __main__ - len of test dataset: 1646
2023-06-27 21:33:53,790 - 0:43:14 - 766.7s - INFO - __main__ - score: {'sst': None, 'srl': None, 'woz.en': OrderedDict([('em', 4.5565006075334145), ('nf1', 74.84346624079308), ('nem', 51.09356014580801), ('joint_goal_em', 25.637910085054678), ('turn_request_em', 71.38517618469015), ('turn_goal_em', 63.547995139732684), ('avg_dialogue', 48.51154313487241)])}
